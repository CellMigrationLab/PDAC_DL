{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF4zYMmXULP7"
      },
      "source": [
        "# **PDAC CellTracksColab - Plots:**\n",
        "---\n",
        "\n",
        "### Modified CellTracksColab Notebook for Circulating Cell Attachment Analysis\n",
        "\n",
        "<font size = 4>This version of the CellTracksColab notebook has been specifically adapted to analyze the attachment of circulating cells to endothelial cells. It builds upon the original framework to offer specialized functionalities tailored for this complex aspect of cell migration studies.\n",
        "\n",
        "<font size = 4>For reference, the original CellTracksColab notebook and its comprehensive suite of tools can be found at the CellMigrationLab GitHub repository:\n",
        "\n",
        "<font size = 4>[CellMigrationLab/CellTracksColab](https://github.com/CellMigrationLab/CellTracksColab)\n",
        "\n",
        "<font size = 4>This notebook is specifically designed to facilitate the reproduction of plots featured in the paper, allowing for an in-depth examination of the tracking data. It is equipped with the following key features:\n",
        "\n",
        "- **Direct Data Download from Zenodo:** The notebook enables users to seamlessly download the tracking data directly from Zenodo, ensuring easy access to the necessary datasets for analysis without the need for manual data handling.\n",
        "\n",
        "- **Customizable Plotting Options:** Users are provided with the flexibility to select and replot various track metrics according to their interests. This feature allows for personalized exploration beyond the analysis presented in the paper, catering to specific investigative needs.\n",
        "\n",
        "\n",
        "<font size = 4>Notebook created by [Guillaume Jacquemet](https://cellmig.org/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JrkfFr7mgZmA"
      },
      "outputs": [],
      "source": [
        "# @title #MIT License\n",
        "\n",
        "print(\"\"\"\n",
        "**MIT License**\n",
        "\n",
        "Copyright (c) 2023 Guillaume Jacquemet\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4-Ft-yNRVCc"
      },
      "source": [
        "--------------------------------------------------------\n",
        "# **Part 1: Prepare the session and load your data**\n",
        "--------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h0prdayn0qG"
      },
      "source": [
        "## **1.1. Install key dependencies**\n",
        "---\n",
        "<font size = 4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rAP0ahCzn1V6"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play to install\n",
        "!pip -q install pandas scikit-learn\n",
        "!pip -q install hdbscan\n",
        "!pip -q install umap-learn\n",
        "!pip -q install plotly\n",
        "!pip -q install tqdm\n",
        "!pip -q install gdown\n",
        "!pip -q install -U -q PyDrive\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import numpy as np\n",
        "import itertools\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import requests\n",
        "\n",
        "\n",
        "#----------------------- Key functions -----------------------------#\n",
        "\n",
        "# Function to calculate Cohen's d\n",
        "def cohen_d(group1, group2):\n",
        "    diff = group1.mean() - group2.mean()\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1 = group1.var()\n",
        "    var2 = group2.var()\n",
        "    pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
        "    d = diff / np.sqrt(pooled_var)\n",
        "    return d\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "def save_dataframe_with_progress(df, path, desc=\"Saving\", chunk_size=50000):\n",
        "    \"\"\"Save a DataFrame with a progress bar.\"\"\"\n",
        "\n",
        "    # Estimating the number of chunks based on the provided chunk size\n",
        "    num_chunks = int(len(df) / chunk_size) + 1\n",
        "\n",
        "    # Create a tqdm instance for progress tracking\n",
        "    with tqdm(total=len(df), unit=\"rows\", desc=desc) as pbar:\n",
        "        # Open the file for writing\n",
        "        with open(path, \"w\") as f:\n",
        "            # Write the header once at the beginning\n",
        "            df.head(0).to_csv(f, index=False)\n",
        "\n",
        "            for chunk in np.array_split(df, num_chunks):\n",
        "                chunk.to_csv(f, mode=\"a\", header=False, index=False)\n",
        "                pbar.update(len(chunk))\n",
        "\n",
        "\n",
        "def check_for_nans(df, df_name):\n",
        "    \"\"\"\n",
        "    Checks the given DataFrame for NaN values and prints the count for each column containing NaNs.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): DataFrame to be checked for NaN values.\n",
        "    df_name (str): The name of the DataFrame as a string, used for printing.\n",
        "    \"\"\"\n",
        "    # Check if the DataFrame has any NaN values and print a warning if it does.\n",
        "    nan_columns = df.columns[df.isna().any()].tolist()\n",
        "\n",
        "    if nan_columns:\n",
        "        for col in nan_columns:\n",
        "            nan_count = df[col].isna().sum()\n",
        "            print(f\"Column '{col}' in {df_name} contains {nan_count} NaN values.\")\n",
        "    else:\n",
        "        print(f\"No NaN values found in {df_name}.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kzd_8GUnpbw"
      },
      "source": [
        "## **1.2. Mount your Google Drive**\n",
        "---\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the instructions.\n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GA1wCrkoV4i5"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsDAwkSOo1gV"
      },
      "source": [
        "## **1.3. Download the dataset from Zenodo**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Download the dataset\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "import gdown\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "\n",
        "\n",
        "file_id = '1bjdoAEoOPROJ5JYJ5V6dLA-3AI-iNOVW'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/merged_Tracks.csv')  # Replace with your file name and extension\n",
        "\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "\n",
        "file_id = '1GAoZxiQbQ85pgW-Y3PvcGw8JbfZkkP32'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/slow_tracks_count_adjusted.csv')  # Replace with your file name and extension\n",
        "\n",
        "#@markdown ###Provide the path to your Result folder\n",
        "\n",
        "Results_Folder = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "if not Results_Folder:\n",
        "    Results_Folder = '/content/Results'  # Default Results_Folder path if not defined\n",
        "\n",
        "if not os.path.exists(Results_Folder):\n",
        "    os.makedirs(Results_Folder)  # Create Results_Folder if it doesn't exist\n",
        "\n",
        "# Print the location of the result folder\n",
        "print(f\"Result folder is located at: {Results_Folder}\")\n",
        "\n",
        "# For existing dataframes\n",
        "\n",
        "print(\"Loading track table file....\")\n",
        "merged_tracks_df = pd.read_csv(\"/content/merged_Tracks.csv\", low_memory=False)\n",
        "\n",
        "\n",
        "check_for_nans(merged_tracks_df, \"merged_tracks_df\")\n",
        "\n",
        "\n",
        "print(\"Loading track table file....\")\n",
        "count_df = pd.read_csv(\"/content/slow_tracks_count_adjusted.csv\", low_memory=False)\n",
        "\n",
        "check_for_nans(count_df, \"count_df\")\n",
        "\n",
        "print(f\"Done\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vxLnSGChrZTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joRI14WVUPuM"
      },
      "source": [
        "-------------------------------------------\n",
        "\n",
        "# **Part 2. Plot track parameters**\n",
        "-------------------------------------------\n",
        "\n",
        "##**Statistical analyses**\n",
        "### Cohen's d (Effect Size):\n",
        "<font size = 4>Cohen's d measures the size of the difference between two groups, normalized by their pooled standard deviation. Values can be interpreted as small (0 to 0.2), medium (0.2 to 0.5), or large (0.5 and above) effects. It helps quantify how significant the observed difference is, beyond just being statistically significant.\n",
        "\n",
        "### Randomization Test:\n",
        "<font size = 4>This non-parametric test evaluates if observed differences between conditions could have arisen by random chance. It shuffles condition labels multiple times, recalculating the Cohen's d each time. The resulting p-value, which indicates the likelihood of observing the actual difference by chance, provides evidence against the null hypothesis: a smaller p-value implies stronger evidence against the null.\n",
        "\n",
        "### Bonferroni Correction:\n",
        "<font size = 4>Given multiple comparisons, the Bonferroni Correction adjusts significance thresholds to mitigate the risk of false positives. By dividing the standard significance level (alpha) by the number of tests, it ensures that only robust findings are considered significant. However, it's worth noting that this method can be conservative, sometimes overlooking genuine effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MIhsPZp96z8z"
      },
      "outputs": [],
      "source": [
        "# @title ##Plot track parameters\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import ipywidgets as widgets\n",
        "from matplotlib.ticker import FixedLocator\n",
        "\n",
        "# Check and create necessary directories\n",
        "if not os.path.exists(f\"{Results_Folder}/track_parameters_plots\"):\n",
        "    os.makedirs(f\"{Results_Folder}/track_parameters_plots\")\n",
        "\n",
        "if not os.path.exists(f\"{Results_Folder}/track_parameters_plots/pdf\"):\n",
        "    os.makedirs(f\"{Results_Folder}/track_parameters_plots/pdf\")\n",
        "\n",
        "if not os.path.exists(f\"{Results_Folder}/track_parameters_plots/csv\"):\n",
        "    os.makedirs(f\"{Results_Folder}/track_parameters_plots/csv\")\n",
        "\n",
        "# Helper functions\n",
        "def cohen_d(group1, group2):\n",
        "    \"\"\"Compute Cohen's d.\"\"\"\n",
        "    mean_diff = group1.mean() - group2.mean()\n",
        "    pooled_var = (len(group1) * group1.var() + len(group2) * group2.var()) / (len(group1) + len(group2))\n",
        "    d = mean_diff / pooled_var**0.5\n",
        "    return d\n",
        "\n",
        "def get_selectable_columns(df):\n",
        "    \"\"\"Get columns that can be plotted.\"\"\"\n",
        "    exclude_cols = ['Condition', 'File_name', 'Flow_speed', 'Cells', 'ILbeta', 'Repeat', 'Unique_ID',\n",
        "                    'experiment_nb', 'LABEL', 'TRACK_INDEX', 'TRACK_ID', 'TRACK_X_LOCATION',\n",
        "                    'TRACK_Y_LOCATION', 'TRACK_Z_LOCATION']\n",
        "    return [col for col in df.columns if col not in exclude_cols]\n",
        "\n",
        "def display_variable_checkboxes(selectable_columns):\n",
        "    \"\"\"Display checkboxes for selecting variables.\"\"\"\n",
        "    variable_checkboxes = [widgets.Checkbox(value=False, description=col) for col in selectable_columns]\n",
        "    display(widgets.VBox([\n",
        "        widgets.Label('Variables to Plot:'),\n",
        "        widgets.GridBox(variable_checkboxes, layout=widgets.Layout(grid_template_columns=\"repeat(%d, 300px)\" % 3))\n",
        "    ]))\n",
        "    return variable_checkboxes\n",
        "\n",
        "\n",
        "def create_filename(base, selected_cells, selected_speeds, selected_ilbetas, var):\n",
        "    \"\"\"Create a unique filename based on selected options.\"\"\"\n",
        "    def summarize_options(options):\n",
        "        if len(options) > 3:\n",
        "            return f\"{len(options)}options\"\n",
        "        return \"_\".join(options)\n",
        "\n",
        "    selected_options = \"_\".join([\n",
        "        summarize_options(selected_cells),\n",
        "        summarize_options(selected_speeds),\n",
        "        summarize_options(selected_ilbetas)\n",
        "    ])\n",
        "\n",
        "    filename = f\"{base}_{selected_options}_{var}.pdf\"\n",
        "    return filename.replace(\" \", \"_\")  # Replace spaces with underscores for file compatibility\n",
        "\n",
        "\n",
        "# Create checkboxes for various attributes\n",
        "cells_checkboxes = [widgets.Checkbox(value=False, description=str(cell)) for cell in merged_tracks_df['Cells'].unique()]\n",
        "flow_speed_checkboxes = [widgets.Checkbox(value=False, description=str(speed)) for speed in merged_tracks_df['Flow_speed'].unique()]\n",
        "ilbeta_checkboxes = [widgets.Checkbox(value=False, description=str(ilbeta)) for ilbeta in merged_tracks_df['ILbeta'].unique()]\n",
        "\n",
        "\n",
        "# Display checkboxes\n",
        "display(widgets.VBox([\n",
        "    widgets.Label('Cells:'),\n",
        "    widgets.GridBox(cells_checkboxes, layout=widgets.Layout(grid_template_columns=\"repeat(%d, 100px)\" % 4)),\n",
        "    widgets.Label('Flow Speed:'),\n",
        "    widgets.GridBox(flow_speed_checkboxes, layout=widgets.Layout(grid_template_columns=\"repeat(%d, 100px)\" % 4)),\n",
        "    widgets.Label('ILbeta:'),\n",
        "    widgets.GridBox(ilbeta_checkboxes, layout=widgets.Layout(grid_template_columns=\"repeat(%d, 100px)\" % 4))\n",
        "\n",
        "]))\n",
        "\n",
        "# Convert Flow_speed to string for checkbox matching\n",
        "merged_tracks_df['Flow_speed'] = merged_tracks_df['Flow_speed'].astype(str)\n",
        "\n",
        "# Define the plotting function\n",
        "def plot_selected_vars(button, variable_checkboxes):\n",
        "    print(\"Plotting in progress...\")\n",
        "\n",
        "    # Fetch selected values\n",
        "    selected_cells = [box.description for box in cells_checkboxes if box.value]\n",
        "    selected_speeds = [box.description for box in flow_speed_checkboxes if box.value]\n",
        "    selected_ilbetas = [box.description for box in ilbeta_checkboxes if box.value]\n",
        "    variables_to_plot = [box.description for box in variable_checkboxes if box.value]\n",
        "\n",
        "    # Filter dataframe\n",
        "    filtered_df = merged_tracks_df.copy()\n",
        "    filtered_df = filtered_df[filtered_df['Cells'].isin(selected_cells)]\n",
        "    filtered_df = filtered_df[filtered_df['Flow_speed'].isin(selected_speeds)]\n",
        "    filtered_df = filtered_df[filtered_df['ILbeta'].isin(selected_ilbetas)]\n",
        "\n",
        "    # Initialize matrices for statistics\n",
        "    effect_size_matrices = {}\n",
        "    p_value_matrices = {}\n",
        "    bonferroni_matrices = {}\n",
        "\n",
        "    unique_conditions = filtered_df['Condition'].unique().tolist()\n",
        "    num_comparisons = len(unique_conditions) * (len(unique_conditions) - 1) // 2\n",
        "    alpha = 0.05\n",
        "    corrected_alpha = alpha / num_comparisons\n",
        "    n_iterations = 1000\n",
        "\n",
        "# Loop through each variable to plot\n",
        "    for var in variables_to_plot:\n",
        "\n",
        "      filename = create_filename(\"track_parameters_plots\", selected_cells, selected_speeds, selected_ilbetas, var)\n",
        "      pdf_path = os.path.join(Results_Folder, \"track_parameters_plots\", \"pdf\", filename)\n",
        "      csv_path = os.path.join(Results_Folder, \"track_parameters_plots\", \"csv\", f\"{filename[:-4]}.csv\")  # Remove '.pdf' and add '.csv'\n",
        "\n",
        "      pdf_pages = PdfPages(pdf_path)\n",
        "\n",
        "      effect_size_matrix = pd.DataFrame(index=unique_conditions, columns=unique_conditions)\n",
        "      p_value_matrix = pd.DataFrame(index=unique_conditions, columns=unique_conditions)\n",
        "      bonferroni_matrix = pd.DataFrame(index=unique_conditions, columns=unique_conditions)\n",
        "\n",
        "      for cond1, cond2 in itertools.combinations(unique_conditions, 2):\n",
        "        group1 = filtered_df[filtered_df['Condition'] == cond1][var]\n",
        "        group2 = filtered_df[filtered_df['Condition'] == cond2][var]\n",
        "\n",
        "        original_d = abs(cohen_d(group1, group2))\n",
        "        effect_size_matrix.loc[cond1, cond2] = original_d\n",
        "        effect_size_matrix.loc[cond2, cond1] = original_d  # Mirroring\n",
        "\n",
        "        count_extreme = 0\n",
        "        for i in range(n_iterations):\n",
        "            combined = pd.concat([group1, group2])\n",
        "            shuffled = combined.sample(frac=1, replace=False).reset_index(drop=True)\n",
        "            new_group1 = shuffled[:len(group1)]\n",
        "            new_group2 = shuffled[len(group1):]\n",
        "\n",
        "            new_d = cohen_d(new_group1, new_group2)\n",
        "            if np.abs(new_d) >= np.abs(original_d):\n",
        "                count_extreme += 1\n",
        "\n",
        "        p_value = count_extreme / n_iterations\n",
        "        p_value_matrix.loc[cond1, cond2] = p_value\n",
        "        p_value_matrix.loc[cond2, cond1] = p_value  # Mirroring\n",
        "\n",
        "        # Apply Bonferroni correction\n",
        "        bonferroni_corrected_p_value = min(p_value * num_comparisons, 1.0)\n",
        "        bonferroni_matrix.loc[cond1, cond2] = bonferroni_corrected_p_value\n",
        "        bonferroni_matrix.loc[cond2, cond1] = bonferroni_corrected_p_value  # Mirroring\n",
        "\n",
        "      effect_size_matrices[var] = effect_size_matrix\n",
        "      p_value_matrices[var] = p_value_matrix\n",
        "      bonferroni_matrices[var] = bonferroni_matrix\n",
        "\n",
        "    # Concatenate the three matrices side-by-side\n",
        "      combined_df = pd.concat(\n",
        "        [\n",
        "            effect_size_matrices[var].rename(columns={col: f\"{col} (Effect Size)\" for col in effect_size_matrices[var].columns}),\n",
        "            p_value_matrices[var].rename(columns={col: f\"{col} (P-Value)\" for col in p_value_matrices[var].columns}),\n",
        "            bonferroni_matrices[var].rename(columns={col: f\"{col} (Bonferroni-corrected P-Value)\" for col in bonferroni_matrices[var].columns})\n",
        "        ], axis=1\n",
        "    )\n",
        "\n",
        "    # Save the combined DataFrame to a CSV file\n",
        "      combined_df.to_csv(csv_path)\n",
        "\n",
        "    # Create a new figure\n",
        "      fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "    # Create a gridspec for 2 rows and 4 columns\n",
        "      gs = GridSpec(2, 3, height_ratios=[1.5, 1])\n",
        "\n",
        "    # Create the ax for boxplot using the gridspec\n",
        "      ax_box = fig.add_subplot(gs[0, :])\n",
        "\n",
        "    # Extract the data for this variable\n",
        "      data_for_var = filtered_df[['Condition', var, 'Repeat', 'File_name' ]]\n",
        "\n",
        "    # Save the data_for_var to a CSV for replotting\n",
        "      data_for_var.to_csv(f\"{Results_Folder}/track_parameters_plots/csv/{var}_boxplot_data.csv\", index=False)\n",
        "\n",
        "    # Calculate the Interquartile Range (IQR) using the 25th and 75th percentiles\n",
        "      Q1 = filtered_df[var].quantile(0.25)\n",
        "      Q3 = filtered_df[var].quantile(0.75)\n",
        "      IQR = Q3 - Q1\n",
        "\n",
        "    # Define bounds for the outliers\n",
        "      multiplier = 10\n",
        "      lower_bound = Q1 - multiplier * IQR\n",
        "      upper_bound = Q3 + multiplier * IQR\n",
        "\n",
        "\n",
        "    # Plotting\n",
        "      sns.boxplot(x='Condition', y=var, data=filtered_df, ax=ax_box, color='lightgray')  # Boxplot\n",
        "      sns.stripplot(x='Condition', y=var, data=filtered_df, ax=ax_box, hue='Repeat', dodge=True, jitter=True, alpha=0.2)  # Individual data points\n",
        "      ax_box.set_ylim([max(min(filtered_df[var]), lower_bound), min(max(filtered_df[var]), upper_bound)])\n",
        "      ax_box.set_title(f\"{var}\")\n",
        "      ax_box.set_xlabel('Condition')\n",
        "      ax_box.set_ylabel(var)\n",
        "      tick_labels = ax_box.get_xticklabels()\n",
        "      tick_locations = ax_box.get_xticks()\n",
        "      ax_box.xaxis.set_major_locator(FixedLocator(tick_locations))\n",
        "      ax_box.set_xticklabels(tick_labels, rotation=90)\n",
        "      ax_box.legend(loc='center left', bbox_to_anchor=(1, 0.5), title='Repeat')\n",
        "\n",
        "    # Statistical Analyses and Heatmaps\n",
        "\n",
        "    # Effect Size heatmap ax\n",
        "      ax_d = fig.add_subplot(gs[1, 0])\n",
        "      sns.heatmap(effect_size_matrices[var].fillna(0), annot=True, cmap=\"viridis\", cbar=True, square=True, ax=ax_d, vmax=1)\n",
        "      ax_d.set_title(f\"Effect Size (Cohen's d) for {var}\")\n",
        "\n",
        "    # p-value heatmap ax\n",
        "      ax_p = fig.add_subplot(gs[1, 1])\n",
        "      sns.heatmap(p_value_matrices[var].fillna(1), annot=True, cmap=\"viridis_r\", cbar=True, square=True, ax=ax_p, vmax=0.1)\n",
        "      ax_p.set_title(f\"Randomization Test p-value for {var}\")\n",
        "\n",
        "    # Bonferroni corrected p-value heatmap ax\n",
        "      ax_bonf = fig.add_subplot(gs[1, 2])\n",
        "      sns.heatmap(bonferroni_matrices[var].fillna(1), annot=True, cmap=\"viridis_r\", cbar=True, square=True, ax=ax_bonf, vmax=0.1)\n",
        "      ax_bonf.set_title(f\"Bonferroni-corrected p-value for {var}\")\n",
        "\n",
        "      plt.tight_layout()\n",
        "      pdf_pages.savefig(fig)\n",
        "# Close the PDF\n",
        "      pdf_pages.close()\n",
        "\n",
        "# Display variable checkboxes and button\n",
        "selectable_columns = get_selectable_columns(merged_tracks_df)\n",
        "variable_checkboxes = display_variable_checkboxes(selectable_columns)\n",
        "button = widgets.Button(description=\"Plot Selected Variables\", layout=widgets.Layout(width='400px'))\n",
        "button.on_click(lambda b: plot_selected_vars(b, variable_checkboxes))\n",
        "display(button)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------\n",
        "# **Part 3: Plot Arrest Profiles**\n",
        "--------------------------------------------------------"
      ],
      "metadata": {
        "id": "87sHyVUjS-ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# @title #Filter the data\n",
        "\n",
        "\n",
        "# Global variables to store the selected options\n",
        "global filtered_df\n",
        "filtered_df = pd.DataFrame()\n",
        "\n",
        "global selected_cells, selected_speeds, selected_ilbetas\n",
        "selected_cells, selected_speeds, selected_ilbetas = [], [], []\n",
        "\n",
        "# Function to summarize selected options into a string\n",
        "def summarize_options(options):\n",
        "    return \"_\".join([str(option) for option in options if option])  # Filters out any 'falsy' values like empty strings or None\n",
        "\n",
        "# Function to create a filename based on selected options\n",
        "def create_filename(selected_cells, selected_speeds, selected_ilbetas):\n",
        "    # Join the summarized options for each parameter with an underscore\n",
        "    selected_options = \"_\".join([\n",
        "        summarize_options(selected_cells),\n",
        "        summarize_options(selected_speeds),\n",
        "        summarize_options(selected_ilbetas)\n",
        "    ])\n",
        "\n",
        "    # Replace spaces with underscores and return the filename\n",
        "    filename = f\"{selected_options}\"\n",
        "    return filename.replace(\" \", \"_\")\n",
        "\n",
        "# Create checkboxes for each category\n",
        "cells_checkboxes = [widgets.Checkbox(value=False, description=str(cell)) for cell in count_df['Cells'].unique()]\n",
        "flow_speed_checkboxes = [widgets.Checkbox(value=False, description=str(speed)) for speed in count_df['Flow_speed'].unique()]\n",
        "ilbeta_checkboxes = [widgets.Checkbox(value=False, description=str(ilbeta)) for ilbeta in count_df['ILbeta'].unique()]\n",
        "\n",
        "# Function to filter dataframe and update global variables based on selected checkbox values\n",
        "def filter_dataframe(button):\n",
        "    global filtered_df, selected_cells, selected_speeds, selected_ilbetas\n",
        "\n",
        "    # Trim whitespace and correct cases if necessary\n",
        "    count_df['Cells'] = count_df['Cells'].str.strip()\n",
        "    count_df['Flow_speed'] = count_df['Flow_speed'].str.strip()\n",
        "    count_df['ILbeta'] = count_df['ILbeta'].str.strip()\n",
        "\n",
        "    selected_cells = [box.description for box in cells_checkboxes if box.value]\n",
        "    selected_speeds = [box.description for box in flow_speed_checkboxes if box.value]\n",
        "    selected_ilbetas = [box.description for box in ilbeta_checkboxes if box.value]\n",
        "\n",
        "    # Debugging output\n",
        "    print(\"Selected Cells:\", selected_cells)\n",
        "    print(\"Selected Speeds:\", selected_speeds)\n",
        "    print(\"Selected ILbetas:\", selected_ilbetas)\n",
        "    print(\"Original DF length:\", len(count_df))\n",
        "\n",
        "    filtered_df = count_df[\n",
        "        (count_df['Cells'].isin(selected_cells)) &\n",
        "        (count_df['Flow_speed'].isin(selected_speeds)) &\n",
        "        (count_df['ILbeta'].isin(selected_ilbetas))\n",
        "    ]\n",
        "\n",
        "    # More debugging output\n",
        "    print(\"Filtered DF length:\", len(filtered_df))\n",
        "    if len(filtered_df) == 0:\n",
        "        print(\"No data matched the selected filters. Check filters and data for consistency.\")\n",
        "        print(\"Unique 'Cells' in DataFrame:\", count_df['Cells'].unique())\n",
        "        print(\"Unique 'Flow_speed' in DataFrame:\", count_df['Flow_speed'].unique())\n",
        "        print(\"Unique 'ILbeta' in DataFrame:\", count_df['ILbeta'].unique())\n",
        "\n",
        "    print(\"Done\")\n",
        "\n",
        "# Now call the filter function or trigger the button to filter the dataframe and see the output.\n",
        "\n",
        "\n",
        "# Button to trigger dataframe filtering\n",
        "filter_button = widgets.Button(description=\"Filter Dataframe\")\n",
        "filter_button.on_click(filter_dataframe)\n",
        "\n",
        "# Display checkboxes and button\n",
        "display(widgets.VBox([\n",
        "    widgets.Label('Select Cells:'),\n",
        "    widgets.HBox(cells_checkboxes),\n",
        "    widgets.Label('Select Flow Speed:'),\n",
        "    widgets.HBox(flow_speed_checkboxes),\n",
        "    widgets.Label('Select ILbeta:'),\n",
        "    widgets.HBox(ilbeta_checkboxes),\n",
        "    filter_button\n",
        "]))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5SPbRERi1VLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# @title #Plot selected conditions\n",
        "\n",
        "# Check and create necessary directories\n",
        "if not os.path.exists(f\"{Results_Folder}/Track_Counts\"):\n",
        "    os.makedirs(f\"{Results_Folder}/Track_Counts\")\n",
        "\n",
        "filename = create_filename(selected_cells, selected_speeds, selected_ilbetas)\n",
        "\n",
        "\n",
        "pdf_filepath = os.path.join(Results_Folder + '/Track_Counts/', filename+'_plot.pdf')\n",
        "\n",
        "# Get unique combinations of 'Cells' and 'ILbeta'\n",
        "unique_cells_ilbeta = filtered_df[['Cells', 'ILbeta']].drop_duplicates()\n",
        "\n",
        "# Adjust figure size and layout\n",
        "fig, ax = plt.subplots(figsize=(12, 8))  # Adjusted figure size\n",
        "\n",
        "for _, row in unique_cells_ilbeta.iterrows():\n",
        "    cells, ilbeta = row['Cells'], row['ILbeta']\n",
        "    combo_df = filtered_df[(filtered_df['Cells'] == cells) & (filtered_df['ILbeta'] == ilbeta)]\n",
        "\n",
        "    filepath = os.path.join(Results_Folder + '/Track_Counts/', filename +'_data.csv')\n",
        "    combo_df.to_csv(filepath, index=False)\n",
        "    print(f\"Dataframe for {cells}, {ilbeta} saved to {filepath}\")\n",
        "\n",
        "    sns.lineplot(data=combo_df, x='POSITION_T_REPEAT', y='Unique_ID_Rolling', label=f\"{cells}, {ilbeta}\", errorbar=\"se\")\n",
        "\n",
        "# Manually adjust y-axis limits\n",
        "current_ylim = ax.get_ylim()\n",
        "ax.set_ylim(current_ylim[0], current_ylim[1] * 1.1)\n",
        "\n",
        "# Add horizontal lines for different Flow_speed segments\n",
        "ax.hlines(y=current_ylim[1]*1.00, xmin=0, xmax=87, colors='gray', linestyles='solid', lw=5)\n",
        "ax.hlines(y=current_ylim[1]*1.00, xmin=88, xmax=175, colors='gray', linestyles='solid', lw=5)\n",
        "ax.hlines(y=current_ylim[1]*1.00, xmin=176, xmax=263, colors='gray', linestyles='solid', lw=5)\n",
        "ax.hlines(y=current_ylim[1]*1.00, xmin=264, xmax=350, colors='gray', linestyles='solid', lw=5)\n",
        "\n",
        "ax.text(40, current_ylim[1]*1.03, '300', horizontalalignment='center')\n",
        "ax.text(130, current_ylim[1]*1.03, '200', horizontalalignment='center')\n",
        "ax.text(220, current_ylim[1]*1.03, '100', horizontalalignment='center')\n",
        "ax.text(310, current_ylim[1]*1.03, 'Wash', horizontalalignment='center')\n",
        "\n",
        "ax.set_title('Track Count over Time')\n",
        "ax.set_xlabel('Time (s)')\n",
        "ax.set_ylabel('Number of Tracks')\n",
        "\n",
        "# Place the legend outside the plot on the right\n",
        "ax.legend(title='Conditions', loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a PDF\n",
        "plt.savefig(pdf_filepath)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f\"Plot saved to {pdf_filepath}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ghJ5ELxj1A1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "Y4-Ft-yNRVCc",
        "joRI14WVUPuM",
        "87sHyVUjS-ln"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
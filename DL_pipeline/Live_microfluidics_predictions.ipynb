{"cells":[{"cell_type":"markdown","source":["# **Live Microfluidics Predictions Notebook**\n","---\n","\n","## Introduction\n","\n","<font size = 4> The \"Live Microfluidics Predictions\" Jupyter Notebook is part of a deep learning-based image analysis pipeline designed for processing videos of circulating cells attaching to endothelial monolayers. It incorporates state-of-the-art deep learning models from the [ZeroCostDL4Mic](https://github.com/HenriquesLab/ZeroCostDL4Mic) project, facilitating the segmentation of circulating cells, identification of endothelial cell nuclei, and junctions from microscopy videos.\n","\n","## Pipeline Overview\n","\n","<font size = 4> The notebook is a component of a comprehensive pipeline that processes raw microscopy videos into analyzable data, offering insights into cell attachment dynamics. The steps involved include video pre-processing, cell segmentation, frame selection, artificial labeling, image summation, nuclei segmentation, endothelial cell segmentation, and outline generation.\n","\n","### Key Features\n","\n","- **Cell Segmentation:** Utilizes StarDist models for segmenting circulating cells.\n","- **Frame Selection:** Identifies frames with optimal contrast for further analysis.\n","- **Artificial Labeling:** Applies pix2pix models for simulating staining processes.\n","- **Image Summation:** Aggregates predictions to generate a comprehensive image per video segment.\n","- **Nuclei & Endothelial Cell Segmentation:** Employs StarDist and Cellpose models for detailed segmentation.\n","\n","\n","## Contributing\n","\n","<font size = 4> We encourage contributions that enhance the functionality or extend the capabilities of this pipeline.\n","\n","## Support\n","\n","<font size = 4> For assistance or to address queries, please open an issue in the repository. Our team is committed to providing support and ensuring users can leverage this pipeline effectively for their research needs.\n","\n","<font size = 4>Notebook created by [Guillaume Jacquemet](https://cellmig.org/)\n","\n","\n","\n","\n"],"metadata":{"id":"xP0dMnWPfYJs"}},{"cell_type":"markdown","metadata":{"id":"n4yWFoJNnoin"},"source":["# **1. Initialise the Colab session**\n","\n","\n","\n","\n","---\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DMNHVZfHmbKb"},"source":["\n","## **1.1. Check for GPU access**\n","---\n","\n","<font size = 4> By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n","\n","<font size = 4>Go to **Runtime -> Change the Runtime type**\n","\n","<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n","\n","<font size = 4>**Accelator: GPU** *(Graphics processing unit)*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"zCvebubeSaGY"},"outputs":[],"source":["#@markdown ##Run this cell to check if you have GPU access\n","\n","import tensorflow as tf\n","if tf.test.gpu_device_name()=='':\n","  print('You do not have GPU access.')\n","  print('Did you change your runtime ?')\n","  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n","  print('Expect slow performance. To access GPU try reconnecting later')\n","\n","else:\n","  print('You have GPU access')\n","  !nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"sNIVx8_CLolt"},"source":["## **1.2. Mount your Google Drive**\n","---\n","<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n","\n","<font size = 4> Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive.\n","\n","<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"01Djr8v-5pPk"},"outputs":[],"source":["#@markdown ##Play the cell to connect your Google Drive to Colab\n","\n","\n","# mount user's Google Drive to Google Colab.\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"ayA34Ig09M9X"},"source":["##**1.3. Test OpenCL status**\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"y5H4_pIR9KZg"},"outputs":[],"source":["#@markdown ##test pyclesperanto\n","\n","!pip install -q pyclesperanto-prototype\n","\n","\n","#For pyclesperanto\n","\n","import pyclesperanto_prototype as cle\n","\n","gpu_devices = cle.available_device_names(dev_type=\"gpu\")\n","print(\"Available GPU OpenCL devices:\" + str(gpu_devices))\n","cle.select_device(gpu_devices[0])\n","print(\"Using OpenCL device \" + cle.get_device().name)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"ppXoNkgU9geP"},"outputs":[],"source":["#@markdown ##Fix OpenCL if needed\n","\n","\n","!sudo apt-get update -qq\n","!sudo apt-get purge -qq *nvidia* -y\n","!sudo DEBIAN_FRONTEND=noninteractive apt-get install -qq nvidia-driver-530 -y\n","exit(0)\n"]},{"cell_type":"code","source":["#@markdown ##test pyclesperanto again after install\n","\n","\n","import pyclesperanto_prototype as cle\n","\n","gpu_devices = cle.available_device_names(dev_type=\"gpu\")\n","print(\"Available GPU OpenCL devices:\" + str(gpu_devices))\n","cle.select_device(gpu_devices[0])\n","print(\"Using OpenCL device \" + cle.get_device().name)"],"metadata":{"cellView":"form","id":"Buph5tGqiQBW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdN8B91xZO0x"},"source":["## **1.4. Install StarDist, Cellpose, Pix2pix and dependencies**\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fq21zJVFNASx"},"outputs":[],"source":["#@markdown ## StarDist, Cellpose, Pix2pix, and Dependencies Installation\n","\n","# Install necessary packages\n","!pip install -q tifffile folium==0.2.1 imgaug==0.2.5 PTable zarr imagecodecs wget memory_profiler fpdf2 csbdeep stardist gputools cellpose\n","\n","# Optional: Uncomment the following lines if there's a need to uninstall specific packages\n","# !pip uninstall -y yellowbrick\n","\n","# Load memory_profiler for monitoring memory usage\n","%load_ext memory_profiler\n","\n","# Clone the repository for pix2pix models\n","!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n","\n","# Change directory to the cloned repository and install requirements\n","import os\n","os.chdir('pytorch-CycleGAN-and-pix2pix/')\n","!pip install -r requirements.txt\n","\n","# Optional: Uncomment the following line to force a session restart (useful when required by certain installations)\n","# exit(0)\n"]},{"cell_type":"markdown","source":["## **1.5. Load the dependencies and functions**\n","---\n"],"metadata":{"id":"l9QDvxFSpYQm"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"W-KNaNZ87lnw"},"outputs":[],"source":["#@markdown ##Load the dependencies and functions\n","\n","# Enabling inline plotting and memory profiling\n","%matplotlib inline\n","%load_ext memory_profiler\n","\n","from __future__ import print_function, unicode_literals, absolute_import, division\n","import numpy as np\n","np.random.seed(42)\n","\n","import tensorflow\n","print(tensorflow.__version__)\n","print(\"Tensorflow enabled.\")\n","\n","import imagecodecs\n","\n","# ------- Variable specific to Stardist -------\n","from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available, relabel_image_stardist, random_label_cmap,  relabel_image_stardist, _draw_polygons, export_imagej_rois\n","from stardist.models import Config2D, StarDist2D, StarDistData2D # import objects\n","from stardist.matching import matching_dataset\n","from csbdeep.utils import Path, normalize, download_and_extract_zip_file, plot_history # for loss plot\n","from csbdeep.io import save_tiff_imagej_compatible\n","%matplotlib inline\n","\n","lbl_cmap = random_label_cmap()\n","\n","import os.path\n","from PIL import Image\n","import zarr\n","from zipfile import ZIP_DEFLATED\n","from csbdeep.data import Normalizer, normalize_mi_ma\n","\n","\n","class MyNormalizer(Normalizer):\n","    def __init__(self, mi, ma):\n","            self.mi, self.ma = mi, ma\n","    def before(self, x, axes):\n","        return normalize_mi_ma(x, self.mi, self.ma, dtype=np.float32)\n","    def after(*args, **kwargs):\n","        assert False\n","    @property\n","    def do_after(self):\n","        return False\n","\n","# ------- Common variable to all ZeroCostDL4Mic notebooks -------\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import urllib\n","import shutil\n","from tifffile import imread, imsave\n","import time\n","import wget\n","from pathlib import Path\n","import pandas as pd\n","import csv\n","from skimage import io\n","from sklearn.linear_model import LinearRegression\n","from skimage.util import img_as_uint\n","import matplotlib as mpl\n","from skimage.metrics import structural_similarity\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","from astropy.visualization import simple_norm\n","from skimage import img_as_float32, img_as_ubyte, img_as_float\n","from skimage.util import img_as_ubyte\n","from tqdm import tqdm\n","from fpdf import FPDF, HTMLMixin\n","from datetime import datetime\n","from pip._internal.operations.freeze import freeze\n","import subprocess\n","\n","# For sliders and dropdown menu and progress bar\n","\n","import ipywidgets as widgets\n","\n","# Colors for the warning messages\n","class bcolors:\n","  WARNING = '\\033[31m'\n","W  = '\\033[0m'  # white (normal)\n","R  = '\\033[31m' # red\n","\n","import imageio\n","from skimage import data\n","from skimage import exposure\n","from skimage.exposure import match_histograms\n","import os.path\n","\n","\n","# ------- Common variable to all ZeroCostDL4Mic notebooks -------\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import urllib\n","import os, random\n","import shutil\n","import zipfile\n","from tifffile import imread, imsave\n","import sys\n","from glob import glob\n","from scipy import signal\n","from scipy import ndimage\n","from skimage import io\n","from sklearn.linear_model import LinearRegression\n","from skimage.util import img_as_uint\n","import matplotlib as mpl\n","from skimage.metrics import structural_similarity\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","from astropy.visualization import simple_norm\n","from skimage import img_as_float32\n","from skimage.util import img_as_ubyte\n","from tqdm import tqdm\n","from fpdf import FPDF, HTMLMixin\n","from datetime import datetime\n","import subprocess\n","from pip._internal.operations.freeze import freeze\n","from skimage import data\n","from skimage import filters\n","\n","# ------- Variable specific to Cellpose -------\n","\n","from urllib.parse import urlparse\n","%matplotlib inline\n","from cellpose import models\n","from skimage.util import img_as_ubyte\n","import cv2\n","from cellpose import plot\n","from ipywidgets import interact, interact_manual\n","\n","from scipy.ndimage import gaussian_laplace\n","\n","#For pyclesperanto\n","\n","import pyclesperanto_prototype as cle\n","\n","gpu_devices = cle.available_device_names(dev_type=\"gpu\")\n","print(\"Available GPU OpenCL devices:\" + str(gpu_devices))\n","cle.select_device(gpu_devices[0])\n","print(\"Using OpenCL device \" + cle.get_device().name)\n","\n","# Download the StarDist model\n","\n","pretrained_model_name = \"2D_versatile_fluo\"\n","pretrained_model_path = \"/content/\"+pretrained_model_name\n","\n","if os.path.exists(pretrained_model_path):\n","  shutil.rmtree(pretrained_model_path)\n","os.makedirs(pretrained_model_path)\n","\n","wget.download(\"https://cloud.mpi-cbg.de/index.php/s/1k5Zcy7PpFWRb0Q/download?path=/versatile&files=2D_versatile_fluo.zip\", pretrained_model_path)\n","\n","with zipfile.ZipFile(pretrained_model_path+\"/2D_versatile_fluo.zip\", 'r') as zip_ref:\n","  zip_ref.extractall(pretrained_model_path)\n","\n","h5_file_path = os.path.join(pretrained_model_path, \"weights_best.h5\")\n","\n","\n","# StarDist prediction function\n","\n","def stardist_WF_prediction(timelapse, Saving_folder, StarDist_cancer_cells_WF_model_name, StarDist_cancer_cells_WF_model_path):\n","\n","  # normalize channels independently\n","  axis_norm = (0,1)\n","  model_WF = StarDist2D(None, name = StarDist_cancer_cells_WF_model_name, basedir = StarDist_cancer_cells_WF_model_path)\n","\n","  Number_of_nuclei_list = []\n","  Number_of_frame_list = []\n","\n","  timelapse = normalize(timelapse, 1,99.8, axis=(0,)+tuple(1+np.array(axis_norm)))\n","\n","  n_timepoint = timelapse.shape[0]\n","  prediction_stack = np.zeros((n_timepoint, timelapse.shape[1], timelapse.shape[2]), dtype=np.float32)\n","\n","# Analyse each time points one after the other\n","\n","  for t in range(n_timepoint):\n","    img_t = timelapse[t]\n","    labels, polygons = model_WF.predict_instances(img_t)\n","    prediction_stack[t] = labels\n","    Nuclei_array = polygons['coord']\n","    Nuclei_array2 = [str(t), Nuclei_array.shape[0]]\n","    Number_of_nuclei_list.append(Nuclei_array2)\n","    Number_of_frame_list.append(t)\n","\n","  prediction_stack = img_as_float32(prediction_stack, force_copy=False)\n","\n","# Export a csv file containing the number of nuclei detected at each frame\n","  my_df = pd.DataFrame(Number_of_nuclei_list)\n","  my_df.to_csv(Saving_folder_StarDist_cancer_cells+'/'+str(short_name[0])+'_Nuclei_number.csv', index=False, header=False)\n","  os.chdir(Saving_folder_StarDist_cancer_cells)\n","  imsave(str(short_name[0])+\".tif\", prediction_stack, compression ='zlib')\n","\n","\n","  # Object detected vs frame number\n","  plt.figure(figsize=(20,5))\n","  my_df.plot()\n","  plt.title('Number of objects vs frame number')\n","  plt.ylabel('Number of detected objects')\n","  plt.xlabel('Frame number')\n","  plt.legend()\n","  plt.savefig(Saving_folder_StarDist_cancer_cells+'/'+str(short_name[0])+'_Object_detected_vs_frame_number.png',bbox_inches='tight',pad_inches=0)\n","  plt.show()\n","\n","  del prediction_stack\n","  del timelapse\n","  del model_WF\n","  del Number_of_nuclei_list\n","  del Number_of_frame_list\n","  del my_df\n","\n","\n","# Pix2pix prepare the data function\n","\n","def pix2pix_prepare_data(timelapse):\n","  n_timepoint = timelapse.shape[0]\n","  sharpness_WF_sobel = []\n","  sharpness_WF_laplace = []\n","\n","  for t in range(n_timepoint):\n","    img_t = timelapse[t]\n","    img_t = exposure.equalize_adapthist(img_t, clip_limit=0.03)\n","  # Calculate the gradient of the image in the horizontal and vertical directions using the Sobel operator\n","    grad_x = cv2.Sobel(img_t, cv2.CV_64F, 1, 0, ksize=5)\n","    grad_y = cv2.Sobel(img_t, cv2.CV_64F, 0, 1, ksize=5)\n","\n","  # Calculate the magnitude of the gradient\n","    grad_magnitude = np.sqrt(np.square(grad_x) + np.square(grad_y))\n","\n","  # Calculate the mean of the gradient magnitude\n","    sharpness_sobel = np.mean(grad_magnitude)\n","    sharpness_WF_sobel.append(sharpness_sobel)\n","\n","    log_image = gaussian_laplace(img_t, sigma=1)\n","\n","    # Calculate the variance of the LoG image\n","    sharpness_laplace = np.var(log_image)\n","    sharpness_WF_laplace.append(sharpness_laplace)\n","\n","  threshold_sharpness_sobel = np.percentile(sharpness_WF_sobel, 75)\n","  threshold_sharpness_laplace = np.percentile(sharpness_WF_laplace, 75)\n","\n","\n","  for t in range(n_timepoint):\n","    img_t = timelapse[t]\n","    img_t = exposure.equalize_adapthist(img_t, clip_limit=0.03)\n","\n","  # Calculate the gradient of the image in the horizontal and vertical directions using the Sobel operator\n","    grad_x = cv2.Sobel(img_t, cv2.CV_64F, 1, 0, ksize=5)\n","    grad_y = cv2.Sobel(img_t, cv2.CV_64F, 0, 1, ksize=5)\n","\n","  # Calculate the magnitude of the gradient\n","    grad_magnitude = np.sqrt(np.square(grad_x) + np.square(grad_y))\n","\n","    # Calculate the mean of the gradient magnitude\n","    sharpness_sobel = np.mean(grad_magnitude)\n","\n","    log_image = gaussian_laplace(img_t, sigma=1)\n","\n","    # Calculate the variance of the LoG image\n","    sharpness_laplace = np.var(log_image)\n","\n","    if sharpness_sobel > threshold_sharpness_sobel and sharpness_laplace > threshold_sharpness_laplace:\n","\n","      img_t = 255 * img_t # Now scale by 255\n","      img_t = img_t.astype(np.uint8)\n","      cv2.imwrite(testA_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n","      cv2.imwrite(testB_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n","\n","# Here we create a merged A / A image for the prediction\n","  os.chdir(\"/content\")\n","  !python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A \"$imageA_folder\" --fold_B \"$imageB_folder\" --fold_AB \"$imageAB_folder\"\n","\n","\n","def pix2pix_prepare_data_QC(timelapse):\n","  n_timepoint = timelapse.shape[0]\n","  for t in range(n_timepoint):\n","    img_t = timelapse[t]\n","    img_t = exposure.equalize_adapthist(img_t, clip_limit=0.03)\n","    img_t = 255 * img_t # Now scale by 255\n","    img_t = img_t.astype(np.uint8)\n","    cv2.imwrite(testA_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n","    cv2.imwrite(testB_Folder+\"/\"+short_name[0]+\"_\"+str(t)+\".png\", img_t)\n","# Here we create a merged A / A image for the prediction\n","  os.chdir(\"/content\")\n","  !python pytorch-CycleGAN-and-pix2pix/datasets/combine_A_and_B.py --fold_A \"$imageA_folder\" --fold_B \"$imageB_folder\" --fold_AB \"$imageAB_folder\"\n","\n","\n","\n","# Pix2pix functions\n","def pix2pix_WF(imageAB_folder, Prediction_model_name, Prediction_model_path, Image_min_dim, patch_size, checkpoint, saving_folder):\n","\n","  os.chdir(\"/content\")\n","  #!python pytorch-CycleGAN-and-pix2pix/test.py --dataroot \"$imageAB_folder\" --name \"$Prediction_model_name\" --model pix2pix --no_dropout --preprocess scale_width --load_size $Image_min_dim --crop_size $Image_min_dim --results_dir \"$saving_folder\" --checkpoints_dir \"$Prediction_model_path\" --num_test $n_timepoint --epoch $checkpoint --input_nc \"3\" --output_nc \"3\"\n","  !python pytorch-CycleGAN-and-pix2pix/test.py --dataroot \"$imageAB_folder\" --name \"$Prediction_model_name\" --model pix2pix --no_dropout --preprocess scale_width --load_size $Image_min_dim --crop_size $Image_min_dim --results_dir \"$saving_folder\" --checkpoints_dir \"$Prediction_model_path\" --num_test $n_timepoint --epoch $checkpoint --input_nc \"1\" --output_nc \"1\" --dataset_mode \"aligned\"\n","\n","  Checkpoint_name = \"test_\"+str(checkpoint)\n","\n","  Prediction_results_folder = saving_folder+\"/\"+Prediction_model_name+\"/\"+Checkpoint_name+\"/images\"\n","\n","  Prediction_results_images = os.listdir(Prediction_results_folder)\n","\n","  for f in Prediction_results_images:\n","    if (f.endswith(\"_fake_B.png\")):\n","      shutil.copyfile(Prediction_results_folder+\"/\"+f,saving_folder+\"/\"+f)\n","\n","  shutil.rmtree(saving_folder+\"/\"+Prediction_model_name)\n","\n","# Sum projection functions\n","\n","def generate_sum_projections(input_folder,Saving_folder, name):\n","# Here we check the image dimensions\n","  random_choice = random.choice(os.listdir(input_folder))\n","  x = io.imread(input_folder+\"/\"+random_choice)\n","  Image_Y = x.shape[0]\n","  Image_X = x.shape[1]\n","\n","#Here we load all the images as a stack to generate the projection\n","  n_images = len([name for name in os.listdir(input_folder)])\n","  image_stack = np.zeros((n_images, Image_Y, Image_X))\n","  Images_name = os.listdir(input_folder)\n","  for t in range(n_images):\n","    Image_t = io.imread(input_folder+\"/\"+Images_name[t], as_gray= True)\n","    image_stack[t] = Image_t\n","\n","  sum_projection= np.sum(image_stack, axis=0)\n","  image_stack = 255 * image_stack # Now scale by 255\n","  image_stack = image_stack.astype(np.uint8)\n","  os.chdir(Saving_folder)\n","  imsave(str(short_name[0])+\"_\"+name+\"_stack.tif\", image_stack)\n","  imsave(str(short_name[0])+\"_\"+name+\"_projection.tif\", sum_projection)\n","  del image_stack\n","\n","# Cellpose functions\n","\n","def cellpose_PECAM(Input_folder, Result_folder):\n","  source_image_PECAM = Input_folder+\"/\"+str(short_name[0])+\"_PECAM_projection.tif\"\n","  source_image_PECAM = io.imread(source_image_PECAM)\n","\n","  source_image_DAPI = Input_folder+\"/\"+str(short_name[0])+\"_DAPI_projection.tif\"\n","  source_image_DAPI = io.imread(source_image_DAPI)\n","\n","  RGB_image = np.zeros((1024, 1024, 3))\n","\n","  RGB_image[:, :, 0] = source_image_PECAM\n","  RGB_image[:, :, 1] = source_image_DAPI\n","\n","  # Load CellPose parameters\n","  Object_diameter =  0\n","  Flow_threshold = 0.4\n","  Cell_probability_threshold=0\n","  segment_channel = 1\n","  nuclear_channel = 2\n","\n","  channels=[segment_channel,nuclear_channel]\n","  model = models.Cellpose(gpu=True, model_type=\"cyto2\")\n","  print(\"Cytoplasm2 model enabled\")\n","\n","  # CellPose detection\n","  masks, flows, styles, diams = model.eval(RGB_image, diameter=Object_diameter, flow_threshold=Flow_threshold,cellprob_threshold=Cell_probability_threshold, channels=channels)\n","  os.chdir(Result_folder)\n","  imsave(str(short_name[0])+\"_HUVEC_mask.tif\", masks, compression ='zlib')\n","\n","\n","#StarDist for HUVECs\n","\n","def StarDist_endothelial_cells(Input_folder,Result_folder, Prediction_model_name, Prediction_model_path ):\n","  from stardist.models import StarDist2D\n","\n","  source_image_DAPI = Input_folder+\"/\"+str(short_name[0])+\"_DAPI_projection.tif\"\n","  source_image_DAPI = imread(source_image_DAPI)\n","\n","  np.random.seed(32)\n","  lbl_cmap = random_label_cmap()\n","\n","  axis_norm = (0,1)   # normalize channels independently\n","\n","  model_fluo = StarDist2D(None, name = Prediction_model_name, basedir = Prediction_model_path)\n","\n","  img = normalize(source_image_DAPI, 1,99.8, axis = axis_norm)\n","  labels, polygons = model_fluo.predict_instances(img)\n","\n","  os.chdir(Result_folder)\n","  imsave(str(short_name[0])+\"_HUVEC_nuclei.tif\", labels, compression ='zlib')\n","\n","def detect_label_edges(labelimages, Result_folder):\n","  labelimages = io.imread(labelimages)\n","  edges = filters.sobel(labelimages)\n","  edges = exposure.equalize_adapthist(edges, clip_limit=0.03)\n","  edges = 255 * edges # Now scale by 255\n","  edges[edges>0]=1\n","  edges_label = labelimages*edges\n","  os.chdir(Result_folder)\n","  imsave(str(short_name[0])+\"_HUVEC_junctions.tif\", edges_label, compression ='zlib')\n","\n","\n","def detect_label_edges_Clij(labelimages, Result_folder):\n","  labelimages = io.imread(labelimages)\n","  Image_Y = labelimages.shape[0]\n","  Image_X = labelimages.shape[1]\n","  edge_image_destination = np.zeros((Image_Y, Image_X), dtype = np.uint16)\n","  edge_image_destination_2 = np.zeros((Image_Y, Image_X), dtype = np.uint16)\n","  edge_image_destination = cle.detect_label_edges(labelimages)\n","  edge_image_destination = cle.pull(edge_image_destination)\n","  edge_image_destination_2 = np.multiply(labelimages, edge_image_destination)\n","  os.chdir(Result_folder)\n","  imsave(str(short_name[0])+\"_HUVEC_junctions.tif\", edge_image_destination_2, compression ='zlib')\n","\n","\n","def colorize(im, color, clip_percentile=0.1):\n","    \"\"\"\n","    Helper function to create an RGB image from a single-channel image using a\n","    specific color.\n","    \"\"\"\n","    # Check that we do just have a 2D image\n","    if im.ndim > 2 and im.shape[2] != 1:\n","        raise ValueError('This function expects a single-channel image!')\n","\n","    # Rescale the image according to how we want to display it\n","    im_scaled = im.astype(np.float32) - np.percentile(im, clip_percentile)\n","    im_scaled = im_scaled / np.percentile(im_scaled, 100 - clip_percentile)\n","    im_scaled = np.clip(im_scaled, 0, 1)\n","\n","    # Need to make sure we have a channels dimension for the multiplication to work\n","    im_scaled = np.atleast_3d(im_scaled)\n","\n","    # Reshape the color (here, we assume channels last)\n","    color = np.asarray(color).reshape((1, 1, -1))\n","    return im_scaled * color\n","\n","def plotresults(Result_folder):\n","  lbl_cmap = random_label_cmap()\n","\n","  random_choice = random.choice(os.listdir(testA_Folder))\n","  InputWF = io.imread(testA_Folder+\"/\"+random_choice, as_gray = True)\n","\n","  #InputWF = io.imread(testA_Folder +\"/\"+short_name[0] +\"_0.png\", as_gray = True)\n","  StarDistCancer = io.imread(Saving_folder_StarDist_cancer_cells +\"/\"+short_name[0] +\".tif\")\n","  StarDistHUVEC = io.imread(Saving_folder +\"/\"+short_name[0] +\"_HUVEC_nuclei.tif\")\n","  Pix2Pix_PECAM = io.imread(Saving_folder +\"/\"+short_name[0] +\"_DAPI_projection.tif\", as_gray = True)\n","  Pix2Pix_PECAM = colorize(Pix2Pix_PECAM, (0, 1, 0), clip_percentile=0.1)\n","  Pix2Pix_DAPI = io.imread(Saving_folder +\"/\"+short_name[0] +\"_PECAM_projection.tif\", as_gray = True)\n","  Pix2Pix_DAPI = colorize(Pix2Pix_DAPI, (1, 0, 1), clip_percentile=1)\n","  Huvec_Mask = io.imread(Saving_folder +\"/\"+short_name[0] +\"_HUVEC_mask.tif\")\n","  Huvec_edges = io.imread(Saving_folder +\"/\"+short_name[0] +\"_HUVEC_junctions.tif\")\n","  im_composite = np.clip(Pix2Pix_DAPI + Pix2Pix_PECAM, 0, 1)\n","\n","  f=plt.figure(figsize=(16,8))\n","  plt.subplot(2,3,1)\n","  plt.imshow(StarDistCancer[0], cmap=lbl_cmap, interpolation='nearest')\n","  plt.title('Cancer cells')\n","  plt.axis('off');\n","  plt.subplot(2,3,2)\n","  plt.imshow(InputWF, cmap=\"gray\", interpolation='nearest')\n","  plt.title('Input')\n","  plt.axis('off');\n","  plt.subplot(2,3,3)\n","  plt.imshow(im_composite, interpolation='nearest')\n","  plt.title('Pix2Pix predictions')\n","  plt.axis('off');\n","  plt.subplot(2,3,4)\n","  plt.imshow(StarDistHUVEC, cmap=lbl_cmap, interpolation='nearest')\n","  plt.title('HUVEC nuclei')\n","  plt.axis('off');\n","  plt.subplot(2,3,5)\n","  plt.imshow(Huvec_Mask, cmap=lbl_cmap, interpolation='nearest')\n","  plt.title('HUVECs segmentation')\n","  plt.axis('off');\n","  plt.subplot(2,3,6)\n","  plt.imshow(Huvec_edges, cmap=lbl_cmap, interpolation='nearest')\n","  plt.title('HUVEC junctions')\n","  plt.axis('off');\n","  plt.savefig(Result_folder+'/'+str(short_name[0])+'_results.png',bbox_inches='tight',pad_inches=0)\n","  plt.show()\n","\n","print('----------------------------')\n","print(\"Libraries installed\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HLYcZR9gMv42"},"source":["# **2. Select your parameters and paths**\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"y2TD5p7MZrEb"},"outputs":[],"source":["latest = \"latest\"\n","\n","#@markdown #Provide the path to your dataset:\n","\n","Data_folder = \"\" #@param {type:\"string\"}\n","Results_folder = \"\" #@param {type:\"string\"}\n","\n","#@markdown #StarDist models locations:\n","\n","StarDist_model_cancer_cells_WF = \"\" #@param {type:\"string\"}\n","StarDist_model_endothelial_cells = \"\" #@param {type:\"string\"}\n","\n","\n","#@markdown #Pix2pix models locations:\n","\n","#@markdown ###WF to Nuclei:\n","Pix2pix_model_Nuclei = \"\" #@param {type:\"string\"}\n","\n","Pix2pix_model_Nuclei_checkpoint = None#@param {type:\"raw\"}\n","\n","#@markdown ###WF to PECAM:\n","\n","Pix2pix_model_PECAM = \"\" #@param {type:\"string\"}\n","\n","Pix2pix_model_PECAM_checkpoint = None#@param {type:\"raw\"}\n","\n","# Here we check that the StarDist models exist\n","\n","StarDist_cancer_cells_WF_model_name = os.path.basename(StarDist_model_cancer_cells_WF)\n","StarDist_cancer_cells_WF_model_path = os.path.dirname(StarDist_model_cancer_cells_WF)\n","\n","StarDist_cancer_cells_full_model_path = StarDist_cancer_cells_WF_model_path+'/'+StarDist_cancer_cells_WF_model_name+'/'\n","\n","# Here we check that the pix2pix models exist\n","if os.path.exists(StarDist_cancer_cells_full_model_path):\n","  print(\"The \"+StarDist_cancer_cells_WF_model_name+\" network will be used to detect cancer cells.\")\n","else:\n","  print(bcolors.WARNING+'!! WARNING: The chosen StarDist model for detecting the cancer cells does not exist !!'+W)\n","  print('Please make sure you provide a valid model path and model name before proceeding further.')\n","\n","StarDist_model_endothelial_cells_name = os.path.basename(StarDist_model_endothelial_cells)\n","StarDist_model_endothelial_cells_path = os.path.dirname(StarDist_model_endothelial_cells)\n","\n","StarDist_model_endothelial_cells_full_model_path = StarDist_model_endothelial_cells_path+'/'+StarDist_model_endothelial_cells_name+'/'\n","\n","# Here we check that the pix2pix models exist\n","if os.path.exists(StarDist_model_endothelial_cells_full_model_path):\n","  print(\"The \"+StarDist_model_endothelial_cells_name+\" network will be used to detect cancer cells.\")\n","else:\n","  StarDist_model_endothelial_cells_name = \"fluo\"\n","\n","#Here we find the loaded model name and parent path\n","Pix2pix_model_Nuclei_model_name = os.path.basename(Pix2pix_model_Nuclei)\n","Pix2pix_model_Nuclei_model_path = os.path.dirname(Pix2pix_model_Nuclei)\n","\n","#here we check if the pix2pix model exists\n","Pix2pix_model_Nuclei_full_model_path = Pix2pix_model_Nuclei_model_path+'/'+Pix2pix_model_Nuclei_model_name+'/'\n","\n","if os.path.exists(Pix2pix_model_Nuclei_full_model_path):\n","  print(\"The \"+Pix2pix_model_Nuclei_model_name+\" network will be used.\")\n","else:\n","  W  = '\\033[0m'  # white (normal)\n","  R  = '\\033[31m' # red\n","  print(R+'!! WARNING: The chosen model does not exist !!'+W)\n","  print('Please make sure you provide a valid model path and model name before proceeding further.')\n","\n","\n","#Here we find the PECAM loaded model name and parent path\n","Pix2pix_model_PECAM_model_name = os.path.basename(Pix2pix_model_PECAM)\n","Pix2pix_model_PECAM_model_path = os.path.dirname(Pix2pix_model_PECAM)\n","\n","#here we check if the pix2pix model exists\n","Pix2pix_model_PECAM_full_model_path = Pix2pix_model_PECAM_model_path+'/'+Pix2pix_model_PECAM_model_name+'/'\n","\n","if os.path.exists(Pix2pix_model_PECAM_full_model_path):\n","  print(\"The \"+Pix2pix_model_PECAM_model_name+\" network will be used.\")\n","else:\n","  W  = '\\033[0m'  # white (normal)\n","  R  = '\\033[31m' # red\n","  print(R+'!! WARNING: The chosen model does not exist !!'+W)\n","  print('Please make sure you provide a valid model path and model name before proceeding further.')\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# **3. Process your data**\n","---"],"metadata":{"id":"4p7Hfnjcl1uH"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"R4tHDCLNK-QS"},"outputs":[],"source":["#@markdown #Let's go\n","\n","#Here we perform the predictions\n","\n","for image in os.listdir(Data_folder):\n","\n","  print(\"Performing prediction on: \"+image)\n","\n","  timelapse = imread(Data_folder+\"/\"+image)\n","\n","  short_name = os.path.splitext(image)\n","\n","  Image_Y = timelapse.shape[1]\n","  Image_X = timelapse.shape[2]\n","  n_timepoint = timelapse.shape[0]\n","\n","  Image_min_dim = 1024\n","  patch_size = 1024\n","\n","  Saving_folder = Results_folder+\"/\"+short_name[0]\n","\n","  if os.path.exists(Saving_folder):\n","    shutil.rmtree(Saving_folder)\n","  os.makedirs(Saving_folder)\n","\n","  #StarDist predictions. Here we identify the cancer cells\n","\n","  Saving_folder_StarDist_cancer_cells = Saving_folder+\"/\"+\"Cancer_cells_StarDist\"\n","  if os.path.exists(Saving_folder_StarDist_cancer_cells):\n","    shutil.rmtree(Saving_folder_StarDist_cancer_cells)\n","  os.makedirs(Saving_folder_StarDist_cancer_cells)\n","\n","  stardist_WF_prediction(timelapse, Saving_folder, StarDist_cancer_cells_WF_model_name, StarDist_cancer_cells_WF_model_path)\n","\n","  #Pix2pix here we predict the nuclei and the cell-cell junction\n","\n","  Saving_path_pix2pix = \"/content/pix2pix\"\n","  if os.path.exists(Saving_path_pix2pix):\n","    shutil.rmtree(Saving_path_pix2pix)\n","  os.makedirs(Saving_path_pix2pix)\n","\n","  imageA_folder = Saving_path_pix2pix+\"/Raw/A\"\n","  os.makedirs(imageA_folder)\n","\n","  imageB_folder = Saving_path_pix2pix+\"/Raw/B\"\n","  os.makedirs(imageB_folder)\n","\n","  imageAB_folder = Saving_path_pix2pix+\"/Raw/AB\"\n","  os.makedirs(imageAB_folder)\n","\n","  testAB_Folder = Saving_path_pix2pix+\"/Raw/AB/test\"\n","  os.makedirs(testAB_Folder)\n","\n","  testA_Folder = Saving_path_pix2pix+\"/Raw/A/test\"\n","  os.makedirs(testA_Folder)\n","\n","  testB_Folder = Saving_path_pix2pix+\"/Raw/B/test\"\n","  os.makedirs(testB_Folder)\n","\n","  Saving_path_pix2pix_WF_DAPI = Saving_path_pix2pix +\"/WF_DAPI\"\n","  os.makedirs(Saving_path_pix2pix_WF_DAPI)\n","\n","  Saving_path_pix2pix_WF_PECAM = Saving_path_pix2pix +\"/WF_PECAM\"\n","  os.makedirs(Saving_path_pix2pix_WF_PECAM)\n","\n","  #pix2pix prepare the data\n","  pix2pix_prepare_data(timelapse)\n","  #pix2pix_prepare_data_QC(timelapse)\n","\n","  #pix2pix nuclei\n","  pix2pix_WF(imageAB_folder, Pix2pix_model_Nuclei_model_name, Pix2pix_model_Nuclei_model_path, Image_min_dim, patch_size, Pix2pix_model_Nuclei_checkpoint, Saving_path_pix2pix_WF_DAPI)\n","\n","  #pix2pix PECAM\n","  pix2pix_WF(imageAB_folder, Pix2pix_model_PECAM_model_name, Pix2pix_model_PECAM_model_path, Image_min_dim, patch_size, Pix2pix_model_PECAM_checkpoint, Saving_path_pix2pix_WF_PECAM)\n","\n","  # Create the SUM projection for DAPI\n","  DAPI = \"DAPI\"\n","  generate_sum_projections(Saving_path_pix2pix_WF_DAPI,Saving_folder, DAPI)\n","\n","  # Create the SUM projection for PECAM\n","  PECAM = \"PECAM\"\n","  generate_sum_projections(Saving_path_pix2pix_WF_PECAM,Saving_folder, PECAM)\n","\n","  # Detect the endothelial cell\n","  cellpose_PECAM(Saving_folder, Saving_folder)\n","\n","  # Detect the endothelial cell nuclei\n","  StarDist_endothelial_cells(Saving_folder, Saving_folder, StarDist_model_endothelial_cells_name, StarDist_model_endothelial_cells_path)\n","\n","  # Detect the endothelial cell junctions\n","  #detect_label_edges(Saving_folder +\"/\"+short_name[0] +\"_HUVEC_mask.tif\", Saving_folder)\n","  detect_label_edges_Clij(Saving_folder +\"/\"+short_name[0] +\"_HUVEC_mask.tif\", Saving_folder)\n","\n","  # make a figure\n","  plotresults(Saving_folder)\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1A26cn0nxWQCv-LuP3UBfyCWlKBGIo0RU","timestamp":1610969691998},{"file_id":"1MmLTCC0nyX3Akb9V4C_OVxM3X_M8u-eX","timestamp":1610543191319},{"file_id":"1paNjUObR5Rcr4BMGADJTz0PQBBLZDPrY","timestamp":1602522500580},{"file_id":"1WZRIoSBNcRUEq4-Rq5M4mDkIaOlEHnxz","timestamp":1588762142860},{"file_id":"10weAY0es-pEfHlACCaBCKK7PmgdoJqdh","timestamp":1587728072051},{"file_id":"10Ze0rFZoooyyTL_OIVWGdFJEhWE6_cSB","timestamp":1586789421439},{"file_id":"1SsGyUbWcMaLGHFepMuKElRNYLdEBUwf6","timestamp":1583244509550}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}